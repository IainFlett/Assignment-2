{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fc1261-4bff-464b-b430-801fdeea9354",
   "metadata": {},
   "source": [
    "# **Assignment 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d759ac-84e6-456f-8586-b2f745de8eda",
   "metadata": {},
   "source": [
    "|  Name | Student ID | Section Contributed | Section Edited | Other Contributions |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Dueck, Ellie | 301462367 |  |  | \n",
    "| Flett, Iain | 301581520 |  | | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac0d36c-fb99-4c5f-95aa-16d3dec5b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c69f32-61e4-448e-ac44-27ae88951c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores_neg(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['neg']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_com(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['compound']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_pos(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['pos']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_neu(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['neu']\n",
    "    out = (score*100)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a636a2-8dce-47d8-86ff-1cd8a361c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a581bcc-72d6-416d-9ede-f43b1da91792",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6361e19-3c2a-4437-bb9c-4560ff25566d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your best photographs of 2012. GALLERY: http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London's leading shares have fallen amid fears...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Pictures: New Year's celebrations from arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A painting bought for £400 and featured on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52 jobs in 52 weeks. 30-year-old Matt Frost de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>Now just hours until Tim Peake starts his #spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>The designers think it will attract more women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>One of the six is in a coma after the trial on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>A 'historic moment for Great Britain' as Tim P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>The sixth #GOPdebate wasn't for the faint of h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9969 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "0     Your best photographs of 2012. GALLERY: http:/...\n",
       "1     London's leading shares have fallen amid fears...\n",
       "2     In Pictures: New Year's celebrations from arou...\n",
       "3     A painting bought for £400 and featured on the...\n",
       "4     52 jobs in 52 weeks. 30-year-old Matt Frost de...\n",
       "...                                                 ...\n",
       "9964  Now just hours until Tim Peake starts his #spa...\n",
       "9965  The designers think it will attract more women...\n",
       "9966  One of the six is in a coma after the trial on...\n",
       "9967  A 'historic moment for Great Britain' as Tim P...\n",
       "9968  The sixth #GOPdebate wasn't for the faint of h...\n",
       "\n",
       "[9969 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./data/news1short.csv', encoding = \"utf-8\")\n",
    "\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85aa1612-dfe2-4e61-90fa-59d69db8a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roberts took the unusual step of devoting the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you agree with the new law?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some pretty cool confetti will rain down on Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The pharmacy was held up by a man seeking pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>VIDEO: Families of Sandy Hook victims announce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9966</th>\n",
       "      <td>Families of Sandy Hook victims announce websit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>VIDEO: Residents warned to be vigilant after l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>Dad adds magical elements to 6-year-old daught...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9969 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "0     Roberts took the unusual step of devoting the ...\n",
       "1                        Do you agree with the new law?\n",
       "2     Some pretty cool confetti will rain down on Ne...\n",
       "3                                                   NaN\n",
       "4     The pharmacy was held up by a man seeking pres...\n",
       "...                                                 ...\n",
       "9964                                                NaN\n",
       "9965  VIDEO: Families of Sandy Hook victims announce...\n",
       "9966  Families of Sandy Hook victims announce websit...\n",
       "9967  VIDEO: Residents warned to be vigilant after l...\n",
       "9968  Dad adds magical elements to 6-year-old daught...\n",
       "\n",
       "[9969 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2full = pd.read_csv('./data/news2short.csv', encoding = \"utf-8\")\n",
    "\n",
    "df2 = df2full.head(len(df1))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab9e02fe-e332-4a74-92f2-267f1dd0494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function\n",
    "def featureExtractorNeg(message):\n",
    "    return {'sentiment': get_sentiment_scores_neg(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorCom(message):\n",
    "    return {'sentiment': get_sentiment_scores_com(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorPos(message):\n",
    "    return {'sentiment': get_sentiment_scores_pos(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorNeu(message):\n",
    "    return {'sentiment': get_sentiment_scores_neu(message)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "901b03a1-6098-438b-a9f6-191c54768ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "labeledMessages = ([(message, 'bbc') for message in df1['message']] +\n",
    "                [(message, 'abc') for message in df2['message']])\n",
    "\n",
    "# shuffle the data set\n",
    "random.shuffle(labeledMessages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3399c3-c041-4d44-b00d-178c88c2d864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c08ed15-780f-4e64-b066-b38d9d7ea5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13956\n",
      "3987\n",
      "1993\n"
     ]
    }
   ],
   "source": [
    "# divide 70, 20, 10\n",
    "length = len(labeledMessages)\n",
    "len_training = int(length * 0.7)\n",
    "len_dev = int(length * 0.2)\n",
    "len_test = int(length * 0.1)\n",
    "\n",
    "# print to double-check\n",
    "print(len_training)\n",
    "print(len_dev)\n",
    "print(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ca05176-fbf5-4f9d-ae3c-c2273703e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13956\n",
      "3987\n",
      "1995\n"
     ]
    }
   ],
   "source": [
    "# divide the names list into 3 parts, slicing by the variables above, which tell us how many items\n",
    "# is 70%, 20%, 10%\n",
    "trainingMessages = labeledMessages[:len_training]\n",
    "devtestMessages = labeledMessages[len_training:(len_training + len_dev)]\n",
    "testMessages = labeledMessages[(len_training + len_dev):]\n",
    "\n",
    "# print to double-check\n",
    "print(len(trainingMessages))\n",
    "print(len(devtestMessages))\n",
    "print(len(testMessages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8264fd3d-212c-46e2-ba64-a587f5bbab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc4c8837-1975-43fb-8a34-0c1172c63291",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15fa2185-9e82-4a15-8db4-9631fe9f2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c2a4e4a-c746-4edf-b324-d03f14739260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "684b6651-edc9-4ac5-a3b1-0d907ae506ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35c8ce71-9744-43b4-85d6-044b2861a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "badd8abe-2c5a-4876-bb26-1ae2ff058669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20eca748-390a-4154-a671-6f23440c4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a80f00f-1b57-476a-8115-02d2ca942e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64b0d9a1-250c-4af4-b033-3a81cbca1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dafc42a7-f855-4fbf-ad43-7702279349af",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "448bf601-87e6-4001-8c52-233e381c35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2082bc72-fd1e-48d2-89e6-dabd0b2cc9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4983697015299724\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetNeu)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetNeu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2533be94-1b8f-4d41-bcc6-8cf4bbe8fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5467770253323301\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetNeg)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetNeg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e0dcba5-bbbc-4f02-a1c8-a9031b5281e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625783797341359\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetPos)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetPos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef662b5d-0f7b-4ddc-a68b-bcb1cdd5cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5289691497366441\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetCom)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetCom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c896474a-0236-438a-9823-66e12c2f5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.501\n",
      "             2          -0.62204        0.614\n",
      "             3          -0.61994        0.614\n",
      "             4          -0.61868        0.614\n",
      "             5          -0.61784        0.614\n",
      "             6          -0.61725        0.614\n",
      "             7          -0.61680        0.614\n",
      "             8          -0.61645        0.614\n",
      "             9          -0.61617        0.614\n",
      "            10          -0.61594        0.614\n",
      "            11          -0.61575        0.614\n",
      "            12          -0.61559        0.614\n",
      "            13          -0.61545        0.614\n",
      "            14          -0.61533        0.614\n",
      "            15          -0.61523        0.614\n",
      "            16          -0.61514        0.614\n",
      "            17          -0.61506        0.614\n",
      "            18          -0.61498        0.614\n",
      "            19          -0.61492        0.614\n",
      "            20          -0.61486        0.614\n",
      "            21          -0.61480        0.614\n",
      "            22          -0.61475        0.614\n",
      "            23          -0.61471        0.614\n",
      "            24          -0.61467        0.614\n",
      "            25          -0.61463        0.614\n",
      "            26          -0.61459        0.614\n",
      "            27          -0.61456        0.614\n",
      "            28          -0.61453        0.614\n",
      "            29          -0.61450        0.614\n",
      "            30          -0.61447        0.614\n",
      "            31          -0.61445        0.614\n",
      "            32          -0.61442        0.614\n",
      "            33          -0.61440        0.614\n",
      "            34          -0.61438        0.614\n",
      "            35          -0.61436        0.614\n",
      "            36          -0.61434        0.614\n",
      "            37          -0.61432        0.614\n",
      "            38          -0.61431        0.614\n",
      "            39          -0.61429        0.614\n",
      "            40          -0.61428        0.614\n",
      "            41          -0.61426        0.614\n",
      "            42          -0.61425        0.614\n",
      "            43          -0.61423        0.614\n",
      "            44          -0.61422        0.614\n",
      "            45          -0.61421        0.614\n",
      "            46          -0.61420        0.614\n",
      "            47          -0.61419        0.614\n",
      "            48          -0.61418        0.614\n",
      "            49          -0.61417        0.614\n",
      "            50          -0.61416        0.614\n",
      "            51          -0.61415        0.614\n",
      "            52          -0.61414        0.614\n",
      "            53          -0.61413        0.614\n",
      "            54          -0.61412        0.614\n",
      "            55          -0.61411        0.614\n",
      "            56          -0.61410        0.614\n",
      "            57          -0.61410        0.614\n",
      "            58          -0.61409        0.614\n",
      "            59          -0.61408        0.614\n",
      "            60          -0.61408        0.614\n",
      "            61          -0.61407        0.614\n",
      "            62          -0.61406        0.614\n",
      "            63          -0.61406        0.614\n",
      "            64          -0.61405        0.614\n",
      "            65          -0.61404        0.614\n",
      "            66          -0.61404        0.614\n",
      "            67          -0.61403        0.614\n",
      "            68          -0.61403        0.614\n",
      "            69          -0.61402        0.614\n",
      "            70          -0.61402        0.614\n",
      "            71          -0.61401        0.614\n",
      "            72          -0.61401        0.614\n",
      "            73          -0.61400        0.614\n",
      "            74          -0.61400        0.614\n",
      "            75          -0.61399        0.614\n",
      "            76          -0.61399        0.614\n",
      "            77          -0.61399        0.614\n",
      "            78          -0.61398        0.614\n",
      "            79          -0.61398        0.614\n",
      "            80          -0.61397        0.614\n",
      "            81          -0.61397        0.614\n",
      "            82          -0.61397        0.614\n",
      "            83          -0.61396        0.614\n",
      "            84          -0.61396        0.614\n",
      "            85          -0.61396        0.614\n",
      "            86          -0.61395        0.614\n",
      "            87          -0.61395        0.614\n",
      "            88          -0.61395        0.614\n",
      "            89          -0.61394        0.614\n",
      "            90          -0.61394        0.614\n",
      "            91          -0.61394        0.614\n",
      "            92          -0.61393        0.614\n",
      "            93          -0.61393        0.614\n",
      "            94          -0.61393        0.614\n",
      "            95          -0.61393        0.614\n",
      "            96          -0.61392        0.614\n",
      "            97          -0.61392        0.614\n",
      "            98          -0.61392        0.614\n",
      "            99          -0.61392        0.614\n",
      "         Final          -0.61391        0.614\n",
      "Accuracy on the dev-test set: 0.5605718585402558 \n",
      "\n",
      "   6.644 sentiment==43.5 and label is 'bbc'\n",
      "   6.644 sentiment==53.1 and label is 'bbc'\n",
      "   6.644 sentiment==30.8 and label is 'abc'\n",
      "   6.644 sentiment==44.0 and label is 'bbc'\n",
      "   6.644 sentiment==28.799999999999997 and label is 'bbc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetNeu)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetNeu), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "0aaf680b-eea8-4eaa-8f3f-114d591e39e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.65795        0.575\n",
      "             3          -0.65700        0.575\n",
      "             4          -0.65642        0.575\n",
      "             5          -0.65604        0.575\n",
      "             6          -0.65577        0.575\n",
      "             7          -0.65556        0.575\n",
      "             8          -0.65541        0.575\n",
      "             9          -0.65528        0.575\n",
      "            10          -0.65517        0.575\n",
      "            11          -0.65509        0.575\n",
      "            12          -0.65501        0.575\n",
      "            13          -0.65495        0.575\n",
      "            14          -0.65490        0.575\n",
      "            15          -0.65485        0.575\n",
      "            16          -0.65481        0.575\n",
      "            17          -0.65477        0.575\n",
      "            18          -0.65474        0.575\n",
      "            19          -0.65471        0.575\n",
      "            20          -0.65468        0.575\n",
      "            21          -0.65465        0.575\n",
      "            22          -0.65463        0.575\n",
      "            23          -0.65461        0.575\n",
      "            24          -0.65459        0.575\n",
      "            25          -0.65457        0.575\n",
      "            26          -0.65456        0.575\n",
      "            27          -0.65454        0.575\n",
      "            28          -0.65453        0.575\n",
      "            29          -0.65452        0.575\n",
      "            30          -0.65450        0.575\n",
      "            31          -0.65449        0.575\n",
      "            32          -0.65448        0.575\n",
      "            33          -0.65447        0.575\n",
      "            34          -0.65446        0.575\n",
      "            35          -0.65445        0.575\n",
      "            36          -0.65444        0.575\n",
      "            37          -0.65444        0.575\n",
      "            38          -0.65443        0.575\n",
      "            39          -0.65442        0.575\n",
      "            40          -0.65441        0.575\n",
      "            41          -0.65441        0.575\n",
      "            42          -0.65440        0.575\n",
      "            43          -0.65439        0.575\n",
      "            44          -0.65439        0.575\n",
      "            45          -0.65438        0.575\n",
      "            46          -0.65438        0.575\n",
      "            47          -0.65437        0.575\n",
      "            48          -0.65437        0.575\n",
      "            49          -0.65436        0.575\n",
      "            50          -0.65436        0.575\n",
      "            51          -0.65435        0.575\n",
      "            52          -0.65435        0.575\n",
      "            53          -0.65435        0.575\n",
      "            54          -0.65434        0.575\n",
      "            55          -0.65434        0.575\n",
      "            56          -0.65433        0.575\n",
      "            57          -0.65433        0.575\n",
      "            58          -0.65433        0.575\n",
      "            59          -0.65432        0.575\n",
      "            60          -0.65432        0.575\n",
      "            61          -0.65432        0.575\n",
      "            62          -0.65432        0.575\n",
      "            63          -0.65431        0.575\n",
      "            64          -0.65431        0.575\n",
      "            65          -0.65431        0.575\n",
      "            66          -0.65430        0.575\n",
      "            67          -0.65430        0.575\n",
      "            68          -0.65430        0.575\n",
      "            69          -0.65430        0.575\n",
      "            70          -0.65430        0.575\n",
      "            71          -0.65429        0.575\n",
      "            72          -0.65429        0.575\n",
      "            73          -0.65429        0.575\n",
      "            74          -0.65429        0.575\n",
      "            75          -0.65428        0.575\n",
      "            76          -0.65428        0.575\n",
      "            77          -0.65428        0.575\n",
      "            78          -0.65428        0.575\n",
      "            79          -0.65428        0.575\n",
      "            80          -0.65428        0.575\n",
      "            81          -0.65427        0.575\n",
      "            82          -0.65427        0.575\n",
      "            83          -0.65427        0.575\n",
      "            84          -0.65427        0.575\n",
      "            85          -0.65427        0.575\n",
      "            86          -0.65427        0.575\n",
      "            87          -0.65426        0.575\n",
      "            88          -0.65426        0.575\n",
      "            89          -0.65426        0.575\n",
      "            90          -0.65426        0.575\n",
      "            91          -0.65426        0.575\n",
      "            92          -0.65426        0.575\n",
      "            93          -0.65426        0.575\n",
      "            94          -0.65425        0.575\n",
      "            95          -0.65425        0.575\n",
      "            96          -0.65425        0.575\n",
      "            97          -0.65425        0.575\n",
      "            98          -0.65425        0.575\n",
      "            99          -0.65425        0.575\n",
      "         Final          -0.65425        0.575\n",
      "Accuracy on the dev-test set: 0.5597955301949595 \n",
      "\n",
      "   6.644 sentiment==67.7 and label is 'bbc'\n",
      "   6.644 sentiment==28.4 and label is 'bbc'\n",
      "   6.644 sentiment==49.0 and label is 'bbc'\n",
      "   6.644 sentiment==35.4 and label is 'abc'\n",
      "   6.644 sentiment==44.7 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetNeg)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetNeg), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "7dfa67d6-6949-42e8-9923-961f16c7475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.66524        0.556\n",
      "             3          -0.66382        0.556\n",
      "             4          -0.66297        0.556\n",
      "             5          -0.66240        0.556\n",
      "             6          -0.66200        0.556\n",
      "             7          -0.66170        0.556\n",
      "             8          -0.66146        0.556\n",
      "             9          -0.66127        0.556\n",
      "            10          -0.66112        0.556\n",
      "            11          -0.66099        0.556\n",
      "            12          -0.66088        0.556\n",
      "            13          -0.66079        0.556\n",
      "            14          -0.66071        0.556\n",
      "            15          -0.66063        0.556\n",
      "            16          -0.66057        0.556\n",
      "            17          -0.66052        0.556\n",
      "            18          -0.66047        0.556\n",
      "            19          -0.66042        0.556\n",
      "            20          -0.66038        0.556\n",
      "            21          -0.66035        0.556\n",
      "            22          -0.66031        0.556\n",
      "            23          -0.66028        0.556\n",
      "            24          -0.66025        0.556\n",
      "            25          -0.66023        0.556\n",
      "            26          -0.66020        0.556\n",
      "            27          -0.66018        0.556\n",
      "            28          -0.66016        0.556\n",
      "            29          -0.66014        0.556\n",
      "            30          -0.66012        0.556\n",
      "            31          -0.66010        0.556\n",
      "            32          -0.66009        0.556\n",
      "            33          -0.66007        0.556\n",
      "            34          -0.66006        0.556\n",
      "            35          -0.66005        0.556\n",
      "            36          -0.66003        0.556\n",
      "            37          -0.66002        0.556\n",
      "            38          -0.66001        0.556\n",
      "            39          -0.66000        0.556\n",
      "            40          -0.65999        0.556\n",
      "            41          -0.65998        0.556\n",
      "            42          -0.65997        0.556\n",
      "            43          -0.65996        0.556\n",
      "            44          -0.65995        0.556\n",
      "            45          -0.65994        0.556\n",
      "            46          -0.65994        0.556\n",
      "            47          -0.65993        0.556\n",
      "            48          -0.65992        0.556\n",
      "            49          -0.65991        0.556\n",
      "            50          -0.65991        0.556\n",
      "            51          -0.65990        0.556\n",
      "            52          -0.65989        0.556\n",
      "            53          -0.65989        0.556\n",
      "            54          -0.65988        0.556\n",
      "            55          -0.65988        0.556\n",
      "            56          -0.65987        0.556\n",
      "            57          -0.65987        0.556\n",
      "            58          -0.65986        0.556\n",
      "            59          -0.65986        0.556\n",
      "            60          -0.65985        0.556\n",
      "            61          -0.65985        0.556\n",
      "            62          -0.65984        0.556\n",
      "            63          -0.65984        0.556\n",
      "            64          -0.65984        0.556\n",
      "            65          -0.65983        0.556\n",
      "            66          -0.65983        0.556\n",
      "            67          -0.65982        0.556\n",
      "            68          -0.65982        0.556\n",
      "            69          -0.65982        0.556\n",
      "            70          -0.65981        0.556\n",
      "            71          -0.65981        0.556\n",
      "            72          -0.65981        0.556\n",
      "            73          -0.65980        0.556\n",
      "            74          -0.65980        0.556\n",
      "            75          -0.65980        0.556\n",
      "            76          -0.65980        0.556\n",
      "            77          -0.65979        0.556\n",
      "            78          -0.65979        0.556\n",
      "            79          -0.65979        0.556\n",
      "            80          -0.65978        0.556\n",
      "            81          -0.65978        0.556\n",
      "            82          -0.65978        0.556\n",
      "            83          -0.65978        0.556\n",
      "            84          -0.65977        0.556\n",
      "            85          -0.65977        0.556\n",
      "            86          -0.65977        0.556\n",
      "            87          -0.65977        0.556\n",
      "            88          -0.65977        0.556\n",
      "            89          -0.65976        0.556\n",
      "            90          -0.65976        0.556\n",
      "            91          -0.65976        0.556\n",
      "            92          -0.65976        0.556\n",
      "            93          -0.65976        0.556\n",
      "            94          -0.65975        0.556\n",
      "            95          -0.65975        0.556\n",
      "            96          -0.65975        0.556\n",
      "            97          -0.65975        0.556\n",
      "            98          -0.65975        0.556\n",
      "            99          -0.65974        0.556\n",
      "         Final          -0.65974        0.556\n",
      "Accuracy on the dev-test set: 0.5463623395149786 \n",
      "\n",
      "   6.644 sentiment==51.2 and label is 'bbc'\n",
      "   6.644 sentiment==55.00000000000001 and label is 'bbc'\n",
      "   6.644 sentiment==60.0 and label is 'bbc'\n",
      "   6.644 sentiment==66.10000000000001 and label is 'bbc'\n",
      "   6.644 sentiment==55.900000000000006 and label is 'bbc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetPos)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetPos), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "2a6f9dd8-4e4a-448c-ba9e-1518aa1114f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.64564        0.594\n",
      "             3          -0.63740        0.594\n",
      "             4          -0.63248        0.594\n",
      "             5          -0.62922        0.594\n",
      "             6          -0.62689        0.594\n",
      "             7          -0.62515        0.594\n",
      "             8          -0.62380        0.594\n",
      "             9          -0.62272        0.594\n",
      "            10          -0.62184        0.594\n",
      "            11          -0.62110        0.594\n",
      "            12          -0.62048        0.594\n",
      "            13          -0.61995        0.594\n",
      "            14          -0.61949        0.594\n",
      "            15          -0.61909        0.594\n",
      "            16          -0.61873        0.594\n",
      "            17          -0.61841        0.594\n",
      "            18          -0.61813        0.594\n",
      "            19          -0.61788        0.594\n",
      "            20          -0.61765        0.594\n",
      "            21          -0.61744        0.594\n",
      "            22          -0.61725        0.594\n",
      "            23          -0.61707        0.594\n",
      "            24          -0.61691        0.594\n",
      "            25          -0.61676        0.594\n",
      "            26          -0.61662        0.594\n",
      "            27          -0.61650        0.594\n",
      "            28          -0.61638        0.594\n",
      "            29          -0.61627        0.594\n",
      "            30          -0.61616        0.594\n",
      "            31          -0.61607        0.594\n",
      "            32          -0.61597        0.594\n",
      "            33          -0.61589        0.594\n",
      "            34          -0.61581        0.594\n",
      "            35          -0.61573        0.594\n",
      "            36          -0.61566        0.594\n",
      "            37          -0.61559        0.594\n",
      "            38          -0.61553        0.594\n",
      "            39          -0.61546        0.594\n",
      "            40          -0.61540        0.594\n",
      "            41          -0.61535        0.594\n",
      "            42          -0.61530        0.594\n",
      "            43          -0.61524        0.594\n",
      "            44          -0.61520        0.594\n",
      "            45          -0.61515        0.594\n",
      "            46          -0.61510        0.594\n",
      "            47          -0.61506        0.594\n",
      "            48          -0.61502        0.594\n",
      "            49          -0.61498        0.594\n",
      "            50          -0.61494        0.594\n",
      "            51          -0.61491        0.594\n",
      "            52          -0.61487        0.594\n",
      "            53          -0.61484        0.594\n",
      "            54          -0.61481        0.594\n",
      "            55          -0.61478        0.594\n",
      "            56          -0.61474        0.594\n",
      "            57          -0.61472        0.594\n",
      "            58          -0.61469        0.594\n",
      "            59          -0.61466        0.594\n",
      "            60          -0.61463        0.594\n",
      "            61          -0.61461        0.594\n",
      "            62          -0.61458        0.594\n",
      "            63          -0.61456        0.594\n",
      "            64          -0.61454        0.594\n",
      "            65          -0.61451        0.594\n",
      "            66          -0.61449        0.594\n",
      "            67          -0.61447        0.594\n",
      "            68          -0.61445        0.594\n",
      "            69          -0.61443        0.594\n",
      "            70          -0.61441        0.594\n",
      "            71          -0.61439        0.594\n",
      "            72          -0.61437        0.594\n",
      "            73          -0.61436        0.594\n",
      "            74          -0.61434        0.594\n",
      "            75          -0.61432        0.594\n",
      "            76          -0.61431        0.594\n",
      "            77          -0.61429        0.594\n",
      "            78          -0.61427        0.594\n",
      "            79          -0.61426        0.594\n",
      "            80          -0.61424        0.594\n",
      "            81          -0.61423        0.594\n",
      "            82          -0.61422        0.594\n",
      "            83          -0.61420        0.594\n",
      "            84          -0.61419        0.594\n",
      "            85          -0.61418        0.594\n",
      "            86          -0.61416        0.594\n",
      "            87          -0.61415        0.594\n",
      "            88          -0.61414        0.594\n",
      "            89          -0.61413        0.594\n",
      "            90          -0.61411        0.594\n",
      "            91          -0.61410        0.594\n",
      "            92          -0.61409        0.594\n",
      "            93          -0.61408        0.594\n",
      "            94          -0.61407        0.594\n",
      "            95          -0.61406        0.594\n",
      "            96          -0.61405        0.594\n",
      "            97          -0.61404        0.594\n",
      "            98          -0.61403        0.594\n",
      "            99          -0.61402        0.594\n",
      "         Final          -0.61401        0.594\n",
      "Accuracy on the dev-test set: 0.5524251069900142 \n",
      "\n",
      "   6.644 sentiment==-3.8699999999999997 and label is 'abc'\n",
      "   6.644 sentiment==29.24 and label is 'bbc'\n",
      "   6.644 sentiment==-16.950000000000003 and label is 'bbc'\n",
      "   6.644 sentiment==-62.4 and label is 'bbc'\n",
      "   6.644 sentiment==-93.22 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetCom)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetCom), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "21722634-0cb6-4669-b7c6-a423a5b27810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# create an empty list to store the errors\\nerrors = []\\n\\n# loop through the devtestNames to classify the entire name\\n# store the errors in the list\\nfor (message, tag) in testMessages:\\n    guess = B_classifier.classify(featureExtractor(str(message)))\\n    if guess != tag:\\n        print(\"correct=%s guess=%s name=%s\" % (tag, guess, message))'"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# create an empty list to store the errors\n",
    "errors = []\n",
    "\n",
    "# loop through the devtestNames to classify the entire name\n",
    "# store the errors in the list\n",
    "for (message, tag) in testMessages:\n",
    "    guess = B_classifier.classify(featureExtractor(str(message)))\n",
    "    if guess != tag:\n",
    "        print(\"correct=%s guess=%s name=%s\" % (tag, guess, message))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffaef02-0bca-4dfe-a84c-a09cf495ec17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c7cbf-1816-4d57-a1d6-715f85c200fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64431ba-2b05-4d84-8762-4f64da010b19",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "    SciKit Learn and NLTK package : https://www.youtube.com/watch?v=nla4C-VYNEU&t=272s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc7f3c-6a17-4e41-bb05-6cabe2ab0d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
