{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fc1261-4bff-464b-b430-801fdeea9354",
   "metadata": {},
   "source": [
    "# **Assignment 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d759ac-84e6-456f-8586-b2f745de8eda",
   "metadata": {},
   "source": [
    "|  Name | Student ID | Section Contributed | Section Edited | Other Contributions |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Dueck, Ellie | 301462367 | write-up, cleaning files, result interpretation| all | Formatting\n",
    "| Flett, Iain | 301581520 | Data Collection, Code, write-up | all | File creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafa6cd-3a89-4685-92bc-148c9a298088",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reference:\n",
    "\n",
    "    SciKit Learn and NLTK package : https://www.youtube.com/watch?v=nla4C-VYNEU&t=272s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b537ff-22ca-4744-a676-b2a85701e0cb",
   "metadata": {},
   "source": [
    "### Import Statments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac0d36c-fb99-4c5f-95aa-16d3dec5b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4cebd-09f3-44ff-9782-78af53d19a10",
   "metadata": {},
   "source": [
    "## Creating Functions\n",
    "For finding, reading, and calculating the sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c69f32-61e4-448e-ac44-27ae88951c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores_neg(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['neg']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_com(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['compound']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_pos(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['pos']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_neu(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['neu']\n",
    "    out = (score*100)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a581bcc-72d6-416d-9ede-f43b1da91792",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7088f85-893b-48ce-8ef7-c197bc4bdccb",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "showing the first and last rows of news messages from either the BBC or ABC \\\n",
    "d1 = bbc news data \\\n",
    "d2 = abc news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6361e19-3c2a-4437-bb9c-4560ff25566d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your best photographs of 2012. GALLERY: http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London's leading shares have fallen amid fears...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Pictures: New Year's celebrations from arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A painting bought for £400 and featured on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52 jobs in 52 weeks. 30-year-old Matt Frost de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>#BlackWomenEqualPay has been trending in the U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>Kenyan authorities crack down on illicitly bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>India will have more people than China by 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>'This is life before life happened.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>'Like watching a Mick Fanning  replay.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "0     Your best photographs of 2012. GALLERY: http:/...\n",
       "1     London's leading shares have fallen amid fears...\n",
       "2     In Pictures: New Year's celebrations from arou...\n",
       "3     A painting bought for £400 and featured on the...\n",
       "4     52 jobs in 52 weeks. 30-year-old Matt Frost de...\n",
       "...                                                 ...\n",
       "4991  #BlackWomenEqualPay has been trending in the U...\n",
       "4992  Kenyan authorities crack down on illicitly bre...\n",
       "4993     India will have more people than China by 2022\n",
       "4994               'This is life before life happened.'\n",
       "4995            'Like watching a Mick Fanning  replay.'\n",
       "\n",
       "[4996 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./data/news1short.csv', encoding = \"utf-8\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "85aa1612-dfe2-4e61-90fa-59d69db8a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roberts took the unusual step of devoting the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you agree with the new law?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some pretty cool confetti will rain down on Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The pharmacy was held up by a man seeking pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>After 7 million views in 24 hours, students ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>This Christmas tree illusion is a showstopper....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>How do professional Santas avoid the flu? Stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>Federal officials are urgently asking for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Talk about a sticky mess.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message\n",
       "0     Roberts took the unusual step of devoting the ...\n",
       "1                        Do you agree with the new law?\n",
       "2     Some pretty cool confetti will rain down on Ne...\n",
       "3                                                   NaN\n",
       "4     The pharmacy was held up by a man seeking pres...\n",
       "...                                                 ...\n",
       "4991  After 7 million views in 24 hours, students ar...\n",
       "4992  This Christmas tree illusion is a showstopper....\n",
       "4993  How do professional Santas avoid the flu? Stor...\n",
       "4994  Federal officials are urgently asking for the ...\n",
       "4995                          Talk about a sticky mess.\n",
       "\n",
       "[4996 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2full = pd.read_csv('./data/news2short.csv', encoding = \"utf-8\")\n",
    "\n",
    "df2 = df2full.head(len(df1))\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6dfb82-5597-4845-8e26-923d59d2f95e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab9e02fe-e332-4a74-92f2-267f1dd0494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function\n",
    "def featureExtractorNeg(message):\n",
    "    return {'sentiment': get_sentiment_scores_neg(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorCom(message):\n",
    "    return {'sentiment': get_sentiment_scores_com(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorPos(message):\n",
    "    return {'sentiment': get_sentiment_scores_pos(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorNeu(message):\n",
    "    return {'sentiment': get_sentiment_scores_neu(message)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "901b03a1-6098-438b-a9f6-191c54768ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "labeledMessages = ([(message, 'bbc') for message in df1['message']] +\n",
    "                [(message, 'abc') for message in df2['message']])\n",
    "\n",
    "# shuffle the data set\n",
    "random.shuffle(labeledMessages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8e301-9507-4604-9590-9492e53c42b9",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "for training and evaluation \\\n",
    "split into:\n",
    "- training (70%)\n",
    "- development (20%)\n",
    "- test (10%) categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c08ed15-780f-4e64-b066-b38d9d7ea5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6994\n",
      "1998\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "# divide 70, 20, 10\n",
    "length = len(labeledMessages)\n",
    "len_training = int(length * 0.7)\n",
    "len_dev = int(length * 0.2)\n",
    "len_test = int(length * 0.1)\n",
    "\n",
    "# print to double-check\n",
    "print(len_training)\n",
    "print(len_dev)\n",
    "print(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ca05176-fbf5-4f9d-ae3c-c2273703e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6994\n",
      "1998\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# divide the names list into 3 parts, slicing by the variables above, which tell us how many items\n",
    "# is 70%, 20%, 10%\n",
    "trainingMessages = labeledMessages[:len_training]\n",
    "devtestMessages = labeledMessages[len_training:(len_training + len_dev)]\n",
    "testMessages = labeledMessages[(len_training + len_dev):]\n",
    "\n",
    "# print to double-check\n",
    "print(len(trainingMessages))\n",
    "print(len(devtestMessages))\n",
    "print(len(testMessages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16827d-1a1c-4f1c-a2c6-ffa0448451b3",
   "metadata": {},
   "source": [
    "### Training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8264fd3d-212c-46e2-ba64-a587f5bbab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bc4c8837-1975-43fb-8a34-0c1172c63291",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "15fa2185-9e82-4a15-8db4-9631fe9f2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c2a4e4a-c746-4edf-b324-d03f14739260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "684b6651-edc9-4ac5-a3b1-0d907ae506ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35c8ce71-9744-43b4-85d6-044b2861a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "badd8abe-2c5a-4876-bb26-1ae2ff058669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20eca748-390a-4154-a671-6f23440c4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5a80f00f-1b57-476a-8115-02d2ca942e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64b0d9a1-250c-4af4-b033-3a81cbca1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dafc42a7-f855-4fbf-ad43-7702279349af",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "448bf601-87e6-4001-8c52-233e381c35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2082bc72-fd1e-48d2-89e6-dabd0b2cc9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4774774774774775\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetNeu)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetNeu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2533be94-1b8f-4d41-bcc6-8cf4bbe8fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5225225225225225\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetNeg)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetNeg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7e0dcba5-bbbc-4f02-a1c8-a9031b5281e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505005005005005\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetPos)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetPos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef662b5d-0f7b-4ddc-a68b-bcb1cdd5cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5175175175175175\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetCom)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetCom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c896474a-0236-438a-9823-66e12c2f5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.494\n",
      "             2          -0.62565        0.605\n",
      "             3          -0.62089        0.605\n",
      "             4          -0.61805        0.605\n",
      "             5          -0.61616        0.605\n",
      "             6          -0.61481        0.605\n",
      "             7          -0.61380        0.605\n",
      "             8          -0.61302        0.605\n",
      "             9          -0.61239        0.605\n",
      "            10          -0.61188        0.605\n",
      "            11          -0.61145        0.605\n",
      "            12          -0.61109        0.605\n",
      "            13          -0.61078        0.605\n",
      "            14          -0.61051        0.605\n",
      "            15          -0.61028        0.605\n",
      "            16          -0.61007        0.605\n",
      "            17          -0.60989        0.605\n",
      "            18          -0.60972        0.605\n",
      "            19          -0.60957        0.605\n",
      "            20          -0.60944        0.605\n",
      "            21          -0.60932        0.605\n",
      "            22          -0.60921        0.605\n",
      "            23          -0.60910        0.605\n",
      "            24          -0.60901        0.605\n",
      "            25          -0.60892        0.605\n",
      "            26          -0.60884        0.605\n",
      "            27          -0.60877        0.605\n",
      "            28          -0.60870        0.605\n",
      "            29          -0.60864        0.605\n",
      "            30          -0.60858        0.605\n",
      "            31          -0.60852        0.605\n",
      "            32          -0.60847        0.605\n",
      "            33          -0.60842        0.605\n",
      "            34          -0.60837        0.605\n",
      "            35          -0.60832        0.605\n",
      "            36          -0.60828        0.605\n",
      "            37          -0.60824        0.605\n",
      "            38          -0.60820        0.605\n",
      "            39          -0.60817        0.605\n",
      "            40          -0.60813        0.605\n",
      "            41          -0.60810        0.605\n",
      "            42          -0.60807        0.605\n",
      "            43          -0.60804        0.605\n",
      "            44          -0.60801        0.605\n",
      "            45          -0.60798        0.605\n",
      "            46          -0.60796        0.605\n",
      "            47          -0.60793        0.605\n",
      "            48          -0.60791        0.605\n",
      "            49          -0.60789        0.605\n",
      "            50          -0.60786        0.605\n",
      "            51          -0.60784        0.605\n",
      "            52          -0.60782        0.605\n",
      "            53          -0.60780        0.605\n",
      "            54          -0.60778        0.605\n",
      "            55          -0.60777        0.605\n",
      "            56          -0.60775        0.605\n",
      "            57          -0.60773        0.605\n",
      "            58          -0.60771        0.605\n",
      "            59          -0.60770        0.605\n",
      "            60          -0.60768        0.605\n",
      "            61          -0.60767        0.605\n",
      "            62          -0.60765        0.605\n",
      "            63          -0.60764        0.605\n",
      "            64          -0.60763        0.605\n",
      "            65          -0.60761        0.605\n",
      "            66          -0.60760        0.605\n",
      "            67          -0.60759        0.605\n",
      "            68          -0.60758        0.605\n",
      "            69          -0.60757        0.605\n",
      "            70          -0.60755        0.605\n",
      "            71          -0.60754        0.605\n",
      "            72          -0.60753        0.605\n",
      "            73          -0.60752        0.605\n",
      "            74          -0.60751        0.605\n",
      "            75          -0.60750        0.605\n",
      "            76          -0.60749        0.605\n",
      "            77          -0.60748        0.605\n",
      "            78          -0.60747        0.605\n",
      "            79          -0.60746        0.605\n",
      "            80          -0.60746        0.605\n",
      "            81          -0.60745        0.605\n",
      "            82          -0.60744        0.605\n",
      "            83          -0.60743        0.605\n",
      "            84          -0.60742        0.605\n",
      "            85          -0.60742        0.605\n",
      "            86          -0.60741        0.605\n",
      "            87          -0.60740        0.605\n",
      "            88          -0.60739        0.605\n",
      "            89          -0.60739        0.605\n",
      "            90          -0.60738        0.605\n",
      "            91          -0.60737        0.605\n",
      "            92          -0.60737        0.605\n",
      "            93          -0.60736        0.605\n",
      "            94          -0.60735        0.605\n",
      "            95          -0.60735        0.605\n",
      "            96          -0.60734        0.605\n",
      "            97          -0.60734        0.605\n",
      "            98          -0.60733        0.605\n",
      "            99          -0.60732        0.605\n",
      "         Final          -0.60732        0.605\n",
      "Accuracy on the dev-test set: 0.5325325325325325 \n",
      "\n",
      "   6.644 sentiment==45.300000000000004 and label is 'bbc'\n",
      "   6.644 sentiment==94.3 and label is 'abc'\n",
      "   6.644 sentiment==37.6 and label is 'bbc'\n",
      "   6.644 sentiment==93.5 and label is 'abc'\n",
      "   6.644 sentiment==64.60000000000001 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetNeu)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetNeu), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "0aaf680b-eea8-4eaa-8f3f-114d591e39e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.65795        0.575\n",
      "             3          -0.65700        0.575\n",
      "             4          -0.65642        0.575\n",
      "             5          -0.65604        0.575\n",
      "             6          -0.65577        0.575\n",
      "             7          -0.65556        0.575\n",
      "             8          -0.65541        0.575\n",
      "             9          -0.65528        0.575\n",
      "            10          -0.65517        0.575\n",
      "            11          -0.65509        0.575\n",
      "            12          -0.65501        0.575\n",
      "            13          -0.65495        0.575\n",
      "            14          -0.65490        0.575\n",
      "            15          -0.65485        0.575\n",
      "            16          -0.65481        0.575\n",
      "            17          -0.65477        0.575\n",
      "            18          -0.65474        0.575\n",
      "            19          -0.65471        0.575\n",
      "            20          -0.65468        0.575\n",
      "            21          -0.65465        0.575\n",
      "            22          -0.65463        0.575\n",
      "            23          -0.65461        0.575\n",
      "            24          -0.65459        0.575\n",
      "            25          -0.65457        0.575\n",
      "            26          -0.65456        0.575\n",
      "            27          -0.65454        0.575\n",
      "            28          -0.65453        0.575\n",
      "            29          -0.65452        0.575\n",
      "            30          -0.65450        0.575\n",
      "            31          -0.65449        0.575\n",
      "            32          -0.65448        0.575\n",
      "            33          -0.65447        0.575\n",
      "            34          -0.65446        0.575\n",
      "            35          -0.65445        0.575\n",
      "            36          -0.65444        0.575\n",
      "            37          -0.65444        0.575\n",
      "            38          -0.65443        0.575\n",
      "            39          -0.65442        0.575\n",
      "            40          -0.65441        0.575\n",
      "            41          -0.65441        0.575\n",
      "            42          -0.65440        0.575\n",
      "            43          -0.65439        0.575\n",
      "            44          -0.65439        0.575\n",
      "            45          -0.65438        0.575\n",
      "            46          -0.65438        0.575\n",
      "            47          -0.65437        0.575\n",
      "            48          -0.65437        0.575\n",
      "            49          -0.65436        0.575\n",
      "            50          -0.65436        0.575\n",
      "            51          -0.65435        0.575\n",
      "            52          -0.65435        0.575\n",
      "            53          -0.65435        0.575\n",
      "            54          -0.65434        0.575\n",
      "            55          -0.65434        0.575\n",
      "            56          -0.65433        0.575\n",
      "            57          -0.65433        0.575\n",
      "            58          -0.65433        0.575\n",
      "            59          -0.65432        0.575\n",
      "            60          -0.65432        0.575\n",
      "            61          -0.65432        0.575\n",
      "            62          -0.65432        0.575\n",
      "            63          -0.65431        0.575\n",
      "            64          -0.65431        0.575\n",
      "            65          -0.65431        0.575\n",
      "            66          -0.65430        0.575\n",
      "            67          -0.65430        0.575\n",
      "            68          -0.65430        0.575\n",
      "            69          -0.65430        0.575\n",
      "            70          -0.65430        0.575\n",
      "            71          -0.65429        0.575\n",
      "            72          -0.65429        0.575\n",
      "            73          -0.65429        0.575\n",
      "            74          -0.65429        0.575\n",
      "            75          -0.65428        0.575\n",
      "            76          -0.65428        0.575\n",
      "            77          -0.65428        0.575\n",
      "            78          -0.65428        0.575\n",
      "            79          -0.65428        0.575\n",
      "            80          -0.65428        0.575\n",
      "            81          -0.65427        0.575\n",
      "            82          -0.65427        0.575\n",
      "            83          -0.65427        0.575\n",
      "            84          -0.65427        0.575\n",
      "            85          -0.65427        0.575\n",
      "            86          -0.65427        0.575\n",
      "            87          -0.65426        0.575\n",
      "            88          -0.65426        0.575\n",
      "            89          -0.65426        0.575\n",
      "            90          -0.65426        0.575\n",
      "            91          -0.65426        0.575\n",
      "            92          -0.65426        0.575\n",
      "            93          -0.65426        0.575\n",
      "            94          -0.65425        0.575\n",
      "            95          -0.65425        0.575\n",
      "            96          -0.65425        0.575\n",
      "            97          -0.65425        0.575\n",
      "            98          -0.65425        0.575\n",
      "            99          -0.65425        0.575\n",
      "         Final          -0.65425        0.575\n",
      "Accuracy on the dev-test set: 0.5597955301949595 \n",
      "\n",
      "   6.644 sentiment==67.7 and label is 'bbc'\n",
      "   6.644 sentiment==28.4 and label is 'bbc'\n",
      "   6.644 sentiment==49.0 and label is 'bbc'\n",
      "   6.644 sentiment==35.4 and label is 'abc'\n",
      "   6.644 sentiment==44.7 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetNeg)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetNeg), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7dfa67d6-6949-42e8-9923-961f16c7475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.494\n",
      "             2          -0.64446        0.575\n",
      "             3          -0.63885        0.575\n",
      "             4          -0.63550        0.575\n",
      "             5          -0.63327        0.575\n",
      "             6          -0.63168        0.575\n",
      "             7          -0.63049        0.575\n",
      "             8          -0.62956        0.575\n",
      "             9          -0.62882        0.575\n",
      "            10          -0.62822        0.575\n",
      "            11          -0.62772        0.575\n",
      "            12          -0.62729        0.575\n",
      "            13          -0.62693        0.575\n",
      "            14          -0.62661        0.575\n",
      "            15          -0.62633        0.575\n",
      "            16          -0.62609        0.575\n",
      "            17          -0.62587        0.575\n",
      "            18          -0.62568        0.575\n",
      "            19          -0.62550        0.575\n",
      "            20          -0.62535        0.575\n",
      "            21          -0.62520        0.575\n",
      "            22          -0.62507        0.575\n",
      "            23          -0.62495        0.575\n",
      "            24          -0.62484        0.575\n",
      "            25          -0.62474        0.575\n",
      "            26          -0.62465        0.575\n",
      "            27          -0.62456        0.575\n",
      "            28          -0.62448        0.575\n",
      "            29          -0.62440        0.575\n",
      "            30          -0.62433        0.575\n",
      "            31          -0.62426        0.575\n",
      "            32          -0.62420        0.575\n",
      "            33          -0.62414        0.575\n",
      "            34          -0.62408        0.575\n",
      "            35          -0.62403        0.575\n",
      "            36          -0.62398        0.575\n",
      "            37          -0.62394        0.575\n",
      "            38          -0.62389        0.575\n",
      "            39          -0.62385        0.575\n",
      "            40          -0.62381        0.575\n",
      "            41          -0.62377        0.575\n",
      "            42          -0.62373        0.575\n",
      "            43          -0.62370        0.575\n",
      "            44          -0.62366        0.575\n",
      "            45          -0.62363        0.575\n",
      "            46          -0.62360        0.575\n",
      "            47          -0.62357        0.575\n",
      "            48          -0.62354        0.575\n",
      "            49          -0.62352        0.575\n",
      "            50          -0.62349        0.575\n",
      "            51          -0.62347        0.575\n",
      "            52          -0.62344        0.575\n",
      "            53          -0.62342        0.575\n",
      "            54          -0.62340        0.575\n",
      "            55          -0.62338        0.575\n",
      "            56          -0.62336        0.575\n",
      "            57          -0.62334        0.575\n",
      "            58          -0.62332        0.575\n",
      "            59          -0.62330        0.575\n",
      "            60          -0.62328        0.575\n",
      "            61          -0.62326        0.575\n",
      "            62          -0.62324        0.575\n",
      "            63          -0.62323        0.575\n",
      "            64          -0.62321        0.575\n",
      "            65          -0.62320        0.575\n",
      "            66          -0.62318        0.575\n",
      "            67          -0.62317        0.575\n",
      "            68          -0.62315        0.575\n",
      "            69          -0.62314        0.575\n",
      "            70          -0.62313        0.575\n",
      "            71          -0.62311        0.575\n",
      "            72          -0.62310        0.575\n",
      "            73          -0.62309        0.575\n",
      "            74          -0.62308        0.575\n",
      "            75          -0.62307        0.575\n",
      "            76          -0.62305        0.575\n",
      "            77          -0.62304        0.575\n",
      "            78          -0.62303        0.575\n",
      "            79          -0.62302        0.575\n",
      "            80          -0.62301        0.575\n",
      "            81          -0.62300        0.575\n",
      "            82          -0.62299        0.575\n",
      "            83          -0.62298        0.575\n",
      "            84          -0.62297        0.575\n",
      "            85          -0.62296        0.575\n",
      "            86          -0.62296        0.575\n",
      "            87          -0.62295        0.575\n",
      "            88          -0.62294        0.575\n",
      "            89          -0.62293        0.575\n",
      "            90          -0.62292        0.575\n",
      "            91          -0.62291        0.575\n",
      "            92          -0.62291        0.575\n",
      "            93          -0.62290        0.575\n",
      "            94          -0.62289        0.575\n",
      "            95          -0.62288        0.575\n",
      "            96          -0.62288        0.575\n",
      "            97          -0.62287        0.575\n",
      "            98          -0.62286        0.575\n",
      "            99          -0.62286        0.575\n",
      "         Final          -0.62285        0.575\n",
      "Accuracy on the dev-test set: 0.512012012012012 \n",
      "\n",
      "   6.644 sentiment==55.60000000000001 and label is 'abc'\n",
      "   6.644 sentiment==23.200000000000003 and label is 'bbc'\n",
      "   6.644 sentiment==36.5 and label is 'bbc'\n",
      "   6.644 sentiment==62.4 and label is 'bbc'\n",
      "   6.644 sentiment==24.3 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetPos)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetPos), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a6f9dd8-4e4a-448c-ba9e-1518aa1114f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.494\n",
      "             2          -0.63750        0.603\n",
      "             3          -0.62320        0.603\n",
      "             4          -0.61472        0.603\n",
      "             5          -0.60910        0.603\n",
      "             6          -0.60511        0.603\n",
      "             7          -0.60213        0.603\n",
      "             8          -0.59981        0.603\n",
      "             9          -0.59797        0.603\n",
      "            10          -0.59646        0.603\n",
      "            11          -0.59520        0.603\n",
      "            12          -0.59414        0.603\n",
      "            13          -0.59323        0.603\n",
      "            14          -0.59244        0.603\n",
      "            15          -0.59175        0.603\n",
      "            16          -0.59115        0.603\n",
      "            17          -0.59061        0.603\n",
      "            18          -0.59013        0.603\n",
      "            19          -0.58969        0.603\n",
      "            20          -0.58930        0.603\n",
      "            21          -0.58894        0.603\n",
      "            22          -0.58862        0.603\n",
      "            23          -0.58832        0.603\n",
      "            24          -0.58805        0.603\n",
      "            25          -0.58779        0.603\n",
      "            26          -0.58756        0.603\n",
      "            27          -0.58734        0.603\n",
      "            28          -0.58714        0.603\n",
      "            29          -0.58695        0.603\n",
      "            30          -0.58677        0.603\n",
      "            31          -0.58661        0.603\n",
      "            32          -0.58645        0.603\n",
      "            33          -0.58631        0.603\n",
      "            34          -0.58617        0.603\n",
      "            35          -0.58604        0.603\n",
      "            36          -0.58591        0.603\n",
      "            37          -0.58580        0.603\n",
      "            38          -0.58569        0.603\n",
      "            39          -0.58558        0.603\n",
      "            40          -0.58548        0.603\n",
      "            41          -0.58539        0.603\n",
      "            42          -0.58530        0.603\n",
      "            43          -0.58521        0.603\n",
      "            44          -0.58513        0.603\n",
      "            45          -0.58505        0.603\n",
      "            46          -0.58497        0.603\n",
      "            47          -0.58490        0.603\n",
      "            48          -0.58483        0.603\n",
      "            49          -0.58476        0.603\n",
      "            50          -0.58470        0.603\n",
      "            51          -0.58464        0.603\n",
      "            52          -0.58458        0.603\n",
      "            53          -0.58452        0.603\n",
      "            54          -0.58446        0.603\n",
      "            55          -0.58441        0.603\n",
      "            56          -0.58436        0.603\n",
      "            57          -0.58431        0.603\n",
      "            58          -0.58426        0.603\n",
      "            59          -0.58422        0.603\n",
      "            60          -0.58417        0.603\n",
      "            61          -0.58413        0.603\n",
      "            62          -0.58409        0.603\n",
      "            63          -0.58404        0.603\n",
      "            64          -0.58401        0.603\n",
      "            65          -0.58397        0.603\n",
      "            66          -0.58393        0.603\n",
      "            67          -0.58389        0.603\n",
      "            68          -0.58386        0.603\n",
      "            69          -0.58383        0.603\n",
      "            70          -0.58379        0.603\n",
      "            71          -0.58376        0.603\n",
      "            72          -0.58373        0.603\n",
      "            73          -0.58370        0.603\n",
      "            74          -0.58367        0.603\n",
      "            75          -0.58364        0.603\n",
      "            76          -0.58361        0.603\n",
      "            77          -0.58359        0.603\n",
      "            78          -0.58356        0.603\n",
      "            79          -0.58353        0.603\n",
      "            80          -0.58351        0.603\n",
      "            81          -0.58348        0.603\n",
      "            82          -0.58346        0.603\n",
      "            83          -0.58344        0.603\n",
      "            84          -0.58341        0.603\n",
      "            85          -0.58339        0.603\n",
      "            86          -0.58337        0.603\n",
      "            87          -0.58335        0.603\n",
      "            88          -0.58333        0.603\n",
      "            89          -0.58331        0.603\n",
      "            90          -0.58329        0.603\n",
      "            91          -0.58327        0.603\n",
      "            92          -0.58325        0.603\n",
      "            93          -0.58323        0.603\n",
      "            94          -0.58321        0.603\n",
      "            95          -0.58319        0.603\n",
      "            96          -0.58317        0.603\n",
      "            97          -0.58316        0.603\n",
      "            98          -0.58314        0.603\n",
      "            99          -0.58312        0.603\n",
      "         Final          -0.58311        0.603\n",
      "Accuracy on the dev-test set: 0.5225225225225225 \n",
      "\n",
      "   6.644 sentiment==85.64 and label is 'abc'\n",
      "   6.644 sentiment==-90.22 and label is 'abc'\n",
      "   6.644 sentiment==-83.93 and label is 'abc'\n",
      "   6.644 sentiment==-52.290000000000006 and label is 'bbc'\n",
      "   6.644 sentiment==79.84 and label is 'bbc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetCom)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetCom), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64431ba-2b05-4d84-8762-4f64da010b19",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "    SciKit Learn and NLTK package : https://www.youtube.com/watch?v=nla4C-VYNEU&t=272s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc7f3c-6a17-4e41-bb05-6cabe2ab0d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
