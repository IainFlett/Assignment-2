{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fc1261-4bff-464b-b430-801fdeea9354",
   "metadata": {},
   "source": [
    "# **Assignment 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d759ac-84e6-456f-8586-b2f745de8eda",
   "metadata": {},
   "source": [
    "|  Name | Student ID | Section Contributed | Section Edited | Other Contributions |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Dueck, Ellie | 301462367 |  |  | \n",
    "| Flett, Iain | 301581520 |  | | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac0d36c-fb99-4c5f-95aa-16d3dec5b6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk import punkt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c69f32-61e4-448e-ac44-27ae88951c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_scores_neg(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['neg']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_com(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['compound']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_pos(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['pos']\n",
    "    out = (score*100)\n",
    "    return out\n",
    "\n",
    "def get_sentiment_scores_neu(text):\n",
    "    \"\"\"\n",
    "    Uses VADER within NLTK to calculate sentiment\n",
    "    \n",
    "    Args:\n",
    "        text (str): a string containing the file or text\n",
    "        \n",
    "    Returns: \n",
    "        dict: a dictionary that VADER creates\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    score = scores['neu']\n",
    "    out = (score*100)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a636a2-8dce-47d8-86ff-1cd8a361c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a581bcc-72d6-416d-9ede-f43b1da91792",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6361e19-3c2a-4437-bb9c-4560ff25566d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your best photographs of 2012. GALLERY: http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London's leading shares have fallen amid fears...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Pictures: New Year's celebrations from arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A painting bought for £400 and featured on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52 jobs in 52 weeks. 30-year-old Matt Frost de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21026</th>\n",
       "      <td>Police warn the public not to approach two men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21027</th>\n",
       "      <td>Would you know the difference?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21028</th>\n",
       "      <td>Certainly an interesting find.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21029</th>\n",
       "      <td>'Canadians are obsessed by the rise of Trump -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21030</th>\n",
       "      <td>Six celebrities will take part in the  Strictl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21031 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message\n",
       "0      Your best photographs of 2012. GALLERY: http:/...\n",
       "1      London's leading shares have fallen amid fears...\n",
       "2      In Pictures: New Year's celebrations from arou...\n",
       "3      A painting bought for £400 and featured on the...\n",
       "4      52 jobs in 52 weeks. 30-year-old Matt Frost de...\n",
       "...                                                  ...\n",
       "21026  Police warn the public not to approach two men...\n",
       "21027                     Would you know the difference?\n",
       "21028                     Certainly an interesting find.\n",
       "21029  'Canadians are obsessed by the rise of Trump -...\n",
       "21030  Six celebrities will take part in the  Strictl...\n",
       "\n",
       "[21031 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./data/news1cleaned.csv', encoding = \"utf-16\")\n",
    "\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85aa1612-dfe2-4e61-90fa-59d69db8a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Roberts took the unusual step of devoting the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you agree with the new law?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some pretty cool confetti will rain down on Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The pharmacy was held up by a man seeking pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21026</th>\n",
       "      <td>WATCH: Obi the baby pygmy hippo has splashed i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21027</th>\n",
       "      <td>40 people, mostly children, sickened after vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21028</th>\n",
       "      <td>For updates on #Charlestonshooting vigil, foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21029</th>\n",
       "      <td>Entire arena joins hands and sings 'We Shall O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21030</th>\n",
       "      <td>72 years later, this Japanese-American couple,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21031 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message\n",
       "0      Roberts took the unusual step of devoting the ...\n",
       "1                         Do you agree with the new law?\n",
       "2      Some pretty cool confetti will rain down on Ne...\n",
       "3                                                    NaN\n",
       "4      The pharmacy was held up by a man seeking pres...\n",
       "...                                                  ...\n",
       "21026  WATCH: Obi the baby pygmy hippo has splashed i...\n",
       "21027  40 people, mostly children, sickened after vis...\n",
       "21028  For updates on #Charlestonshooting vigil, foll...\n",
       "21029  Entire arena joins hands and sings 'We Shall O...\n",
       "21030  72 years later, this Japanese-American couple,...\n",
       "\n",
       "[21031 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2full = pd.read_csv('./data/news2cleaned.csv', encoding = \"utf-16\")\n",
    "\n",
    "df2 = df2full.head(len(df1))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab9e02fe-e332-4a74-92f2-267f1dd0494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function\n",
    "def featureExtractorNeg(message):\n",
    "    return {'sentiment': get_sentiment_scores_neg(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorCom(message):\n",
    "    return {'sentiment': get_sentiment_scores_com(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorPos(message):\n",
    "    return {'sentiment': get_sentiment_scores_pos(message)}\n",
    "\n",
    "# define the function\n",
    "def featureExtractorNeu(message):\n",
    "    return {'sentiment': get_sentiment_scores_neu(message)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901b03a1-6098-438b-a9f6-191c54768ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the dataset\n",
    "labeledMessages = ([(message, 'bbc') for message in df1['message']] +\n",
    "                [(message, 'abc') for message in df2['message']])\n",
    "\n",
    "# shuffle the data set\n",
    "random.shuffle(labeledMessages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3399c3-c041-4d44-b00d-178c88c2d864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c08ed15-780f-4e64-b066-b38d9d7ea5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29443\n",
      "8412\n",
      "4206\n"
     ]
    }
   ],
   "source": [
    "# divide 70, 20, 10\n",
    "length = len(labeledMessages)\n",
    "len_training = int(length * 0.7)\n",
    "len_dev = int(length * 0.2)\n",
    "len_test = int(length * 0.1)\n",
    "\n",
    "# print to double-check\n",
    "print(len_training)\n",
    "print(len_dev)\n",
    "print(len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca05176-fbf5-4f9d-ae3c-c2273703e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29443\n",
      "8412\n",
      "4207\n"
     ]
    }
   ],
   "source": [
    "# divide the names list into 3 parts, slicing by the variables above, which tell us how many items\n",
    "# is 70%, 20%, 10%\n",
    "trainingMessages = labeledMessages[:len_training]\n",
    "devtestMessages = labeledMessages[len_training:(len_training + len_dev)]\n",
    "testMessages = labeledMessages[(len_training + len_dev):]\n",
    "\n",
    "# print to double-check\n",
    "print(len(trainingMessages))\n",
    "print(len(devtestMessages))\n",
    "print(len(testMessages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8264fd3d-212c-46e2-ba64-a587f5bbab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc4c8837-1975-43fb-8a34-0c1172c63291",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15fa2185-9e82-4a15-8db4-9631fe9f2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetCom = [(featureExtractorCom(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c2a4e4a-c746-4edf-b324-d03f14739260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "684b6651-edc9-4ac5-a3b1-0d907ae506ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "35c8ce71-9744-43b4-85d6-044b2861a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetNeg = [(featureExtractorNeg(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "badd8abe-2c5a-4876-bb26-1ae2ff058669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "20eca748-390a-4154-a671-6f23440c4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "5a80f00f-1b57-476a-8115-02d2ca942e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetNeu = [(featureExtractorNeu(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "64b0d9a1-250c-4af4-b033-3a81cbca1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function to extract the features from each set\n",
    "\n",
    "trainingSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in trainingMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "dafc42a7-f855-4fbf-ad43-7702279349af",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtestSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in devtestMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "448bf601-87e6-4001-8c52-233e381c35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetPos = [(featureExtractorPos(str(n)), corp) for (n, corp) in testMessages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "2082bc72-fd1e-48d2-89e6-dabd0b2cc9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4938183547313362\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetNeu)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetNeu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "2533be94-1b8f-4d41-bcc6-8cf4bbe8fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556942463147884\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetNeg)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetNeg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "7e0dcba5-bbbc-4f02-a1c8-a9031b5281e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5368521160247266\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetPos)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetPos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "ef662b5d-0f7b-4ddc-a68b-bcb1cdd5cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5174750356633381\n"
     ]
    }
   ],
   "source": [
    "B_classifier = SklearnClassifier(BernoulliNB())\n",
    "\n",
    "B_classifier.train(trainingSetCom)\n",
    "\n",
    "print(nltk.classify.accuracy(B_classifier,devtestSetCom))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "c896474a-0236-438a-9823-66e12c2f5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.65135        0.586\n",
      "             3          -0.65026        0.586\n",
      "             4          -0.64960        0.586\n",
      "             5          -0.64917        0.586\n",
      "             6          -0.64885        0.586\n",
      "             7          -0.64862        0.586\n",
      "             8          -0.64844        0.586\n",
      "             9          -0.64830        0.586\n",
      "            10          -0.64818        0.586\n",
      "            11          -0.64808        0.586\n",
      "            12          -0.64799        0.586\n",
      "            13          -0.64792        0.586\n",
      "            14          -0.64786        0.586\n",
      "            15          -0.64781        0.586\n",
      "            16          -0.64776        0.586\n",
      "            17          -0.64772        0.586\n",
      "            18          -0.64768        0.586\n",
      "            19          -0.64764        0.586\n",
      "            20          -0.64761        0.586\n",
      "            21          -0.64758        0.586\n",
      "            22          -0.64756        0.586\n",
      "            23          -0.64753        0.586\n",
      "            24          -0.64751        0.586\n",
      "            25          -0.64749        0.586\n",
      "            26          -0.64747        0.586\n",
      "            27          -0.64746        0.586\n",
      "            28          -0.64744        0.586\n",
      "            29          -0.64743        0.586\n",
      "            30          -0.64741        0.586\n",
      "            31          -0.64740        0.586\n",
      "            32          -0.64739        0.586\n",
      "            33          -0.64737        0.586\n",
      "            34          -0.64736        0.586\n",
      "            35          -0.64735        0.586\n",
      "            36          -0.64734        0.586\n",
      "            37          -0.64733        0.586\n",
      "            38          -0.64732        0.586\n",
      "            39          -0.64732        0.586\n",
      "            40          -0.64731        0.586\n",
      "            41          -0.64730        0.586\n",
      "            42          -0.64729        0.586\n",
      "            43          -0.64729        0.586\n",
      "            44          -0.64728        0.586\n",
      "            45          -0.64727        0.586\n",
      "            46          -0.64727        0.586\n",
      "            47          -0.64726        0.586\n",
      "            48          -0.64726        0.586\n",
      "            49          -0.64725        0.586\n",
      "            50          -0.64725        0.586\n",
      "            51          -0.64724        0.586\n",
      "            52          -0.64724        0.586\n",
      "            53          -0.64723        0.586\n",
      "            54          -0.64723        0.586\n",
      "            55          -0.64722        0.586\n",
      "            56          -0.64722        0.586\n",
      "            57          -0.64722        0.586\n",
      "            58          -0.64721        0.586\n",
      "            59          -0.64721        0.586\n",
      "            60          -0.64720        0.586\n",
      "            61          -0.64720        0.586\n",
      "            62          -0.64720        0.586\n",
      "            63          -0.64719        0.586\n",
      "            64          -0.64719        0.586\n",
      "            65          -0.64719        0.586\n",
      "            66          -0.64719        0.586\n",
      "            67          -0.64718        0.586\n",
      "            68          -0.64718        0.586\n",
      "            69          -0.64718        0.586\n",
      "            70          -0.64717        0.586\n",
      "            71          -0.64717        0.586\n",
      "            72          -0.64717        0.586\n",
      "            73          -0.64717        0.586\n",
      "            74          -0.64716        0.586\n",
      "            75          -0.64716        0.586\n",
      "            76          -0.64716        0.586\n",
      "            77          -0.64716        0.586\n",
      "            78          -0.64716        0.586\n",
      "            79          -0.64715        0.586\n",
      "            80          -0.64715        0.586\n",
      "            81          -0.64715        0.586\n",
      "            82          -0.64715        0.586\n",
      "            83          -0.64715        0.586\n",
      "            84          -0.64714        0.586\n",
      "            85          -0.64714        0.586\n",
      "            86          -0.64714        0.586\n",
      "            87          -0.64714        0.586\n",
      "            88          -0.64714        0.586\n",
      "            89          -0.64714        0.586\n",
      "            90          -0.64713        0.586\n",
      "            91          -0.64713        0.586\n",
      "            92          -0.64713        0.586\n",
      "            93          -0.64713        0.586\n",
      "            94          -0.64713        0.586\n",
      "            95          -0.64713        0.586\n",
      "            96          -0.64713        0.586\n",
      "            97          -0.64712        0.586\n",
      "            98          -0.64712        0.586\n",
      "            99          -0.64712        0.586\n",
      "         Final          -0.64712        0.586\n",
      "Accuracy on the dev-test set: 0.5588445078459344 \n",
      "\n",
      "   6.644 sentiment==37.7 and label is 'bbc'\n",
      "   6.644 sentiment==40.699999999999996 and label is 'bbc'\n",
      "   6.644 sentiment==38.5 and label is 'bbc'\n",
      "   6.644 sentiment==37.9 and label is 'bbc'\n",
      "   6.644 sentiment==11.899999999999999 and label is 'bbc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetNeu)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetNeu), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "0aaf680b-eea8-4eaa-8f3f-114d591e39e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.65795        0.575\n",
      "             3          -0.65700        0.575\n",
      "             4          -0.65642        0.575\n",
      "             5          -0.65604        0.575\n",
      "             6          -0.65577        0.575\n",
      "             7          -0.65556        0.575\n",
      "             8          -0.65541        0.575\n",
      "             9          -0.65528        0.575\n",
      "            10          -0.65517        0.575\n",
      "            11          -0.65509        0.575\n",
      "            12          -0.65501        0.575\n",
      "            13          -0.65495        0.575\n",
      "            14          -0.65490        0.575\n",
      "            15          -0.65485        0.575\n",
      "            16          -0.65481        0.575\n",
      "            17          -0.65477        0.575\n",
      "            18          -0.65474        0.575\n",
      "            19          -0.65471        0.575\n",
      "            20          -0.65468        0.575\n",
      "            21          -0.65465        0.575\n",
      "            22          -0.65463        0.575\n",
      "            23          -0.65461        0.575\n",
      "            24          -0.65459        0.575\n",
      "            25          -0.65457        0.575\n",
      "            26          -0.65456        0.575\n",
      "            27          -0.65454        0.575\n",
      "            28          -0.65453        0.575\n",
      "            29          -0.65452        0.575\n",
      "            30          -0.65450        0.575\n",
      "            31          -0.65449        0.575\n",
      "            32          -0.65448        0.575\n",
      "            33          -0.65447        0.575\n",
      "            34          -0.65446        0.575\n",
      "            35          -0.65445        0.575\n",
      "            36          -0.65444        0.575\n",
      "            37          -0.65444        0.575\n",
      "            38          -0.65443        0.575\n",
      "            39          -0.65442        0.575\n",
      "            40          -0.65441        0.575\n",
      "            41          -0.65441        0.575\n",
      "            42          -0.65440        0.575\n",
      "            43          -0.65439        0.575\n",
      "            44          -0.65439        0.575\n",
      "            45          -0.65438        0.575\n",
      "            46          -0.65438        0.575\n",
      "            47          -0.65437        0.575\n",
      "            48          -0.65437        0.575\n",
      "            49          -0.65436        0.575\n",
      "            50          -0.65436        0.575\n",
      "            51          -0.65435        0.575\n",
      "            52          -0.65435        0.575\n",
      "            53          -0.65435        0.575\n",
      "            54          -0.65434        0.575\n",
      "            55          -0.65434        0.575\n",
      "            56          -0.65433        0.575\n",
      "            57          -0.65433        0.575\n",
      "            58          -0.65433        0.575\n",
      "            59          -0.65432        0.575\n",
      "            60          -0.65432        0.575\n",
      "            61          -0.65432        0.575\n",
      "            62          -0.65432        0.575\n",
      "            63          -0.65431        0.575\n",
      "            64          -0.65431        0.575\n",
      "            65          -0.65431        0.575\n",
      "            66          -0.65430        0.575\n",
      "            67          -0.65430        0.575\n",
      "            68          -0.65430        0.575\n",
      "            69          -0.65430        0.575\n",
      "            70          -0.65430        0.575\n",
      "            71          -0.65429        0.575\n",
      "            72          -0.65429        0.575\n",
      "            73          -0.65429        0.575\n",
      "            74          -0.65429        0.575\n",
      "            75          -0.65428        0.575\n",
      "            76          -0.65428        0.575\n",
      "            77          -0.65428        0.575\n",
      "            78          -0.65428        0.575\n",
      "            79          -0.65428        0.575\n",
      "            80          -0.65428        0.575\n",
      "            81          -0.65427        0.575\n",
      "            82          -0.65427        0.575\n",
      "            83          -0.65427        0.575\n",
      "            84          -0.65427        0.575\n",
      "            85          -0.65427        0.575\n",
      "            86          -0.65427        0.575\n",
      "            87          -0.65426        0.575\n",
      "            88          -0.65426        0.575\n",
      "            89          -0.65426        0.575\n",
      "            90          -0.65426        0.575\n",
      "            91          -0.65426        0.575\n",
      "            92          -0.65426        0.575\n",
      "            93          -0.65426        0.575\n",
      "            94          -0.65425        0.575\n",
      "            95          -0.65425        0.575\n",
      "            96          -0.65425        0.575\n",
      "            97          -0.65425        0.575\n",
      "            98          -0.65425        0.575\n",
      "            99          -0.65425        0.575\n",
      "         Final          -0.65425        0.575\n",
      "Accuracy on the dev-test set: 0.5597955301949595 \n",
      "\n",
      "   6.644 sentiment==67.7 and label is 'bbc'\n",
      "   6.644 sentiment==28.4 and label is 'bbc'\n",
      "   6.644 sentiment==49.0 and label is 'bbc'\n",
      "   6.644 sentiment==35.4 and label is 'abc'\n",
      "   6.644 sentiment==44.7 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetNeg)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetNeg), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "7dfa67d6-6949-42e8-9923-961f16c7475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.66524        0.556\n",
      "             3          -0.66382        0.556\n",
      "             4          -0.66297        0.556\n",
      "             5          -0.66240        0.556\n",
      "             6          -0.66200        0.556\n",
      "             7          -0.66170        0.556\n",
      "             8          -0.66146        0.556\n",
      "             9          -0.66127        0.556\n",
      "            10          -0.66112        0.556\n",
      "            11          -0.66099        0.556\n",
      "            12          -0.66088        0.556\n",
      "            13          -0.66079        0.556\n",
      "            14          -0.66071        0.556\n",
      "            15          -0.66063        0.556\n",
      "            16          -0.66057        0.556\n",
      "            17          -0.66052        0.556\n",
      "            18          -0.66047        0.556\n",
      "            19          -0.66042        0.556\n",
      "            20          -0.66038        0.556\n",
      "            21          -0.66035        0.556\n",
      "            22          -0.66031        0.556\n",
      "            23          -0.66028        0.556\n",
      "            24          -0.66025        0.556\n",
      "            25          -0.66023        0.556\n",
      "            26          -0.66020        0.556\n",
      "            27          -0.66018        0.556\n",
      "            28          -0.66016        0.556\n",
      "            29          -0.66014        0.556\n",
      "            30          -0.66012        0.556\n",
      "            31          -0.66010        0.556\n",
      "            32          -0.66009        0.556\n",
      "            33          -0.66007        0.556\n",
      "            34          -0.66006        0.556\n",
      "            35          -0.66005        0.556\n",
      "            36          -0.66003        0.556\n",
      "            37          -0.66002        0.556\n",
      "            38          -0.66001        0.556\n",
      "            39          -0.66000        0.556\n",
      "            40          -0.65999        0.556\n",
      "            41          -0.65998        0.556\n",
      "            42          -0.65997        0.556\n",
      "            43          -0.65996        0.556\n",
      "            44          -0.65995        0.556\n",
      "            45          -0.65994        0.556\n",
      "            46          -0.65994        0.556\n",
      "            47          -0.65993        0.556\n",
      "            48          -0.65992        0.556\n",
      "            49          -0.65991        0.556\n",
      "            50          -0.65991        0.556\n",
      "            51          -0.65990        0.556\n",
      "            52          -0.65989        0.556\n",
      "            53          -0.65989        0.556\n",
      "            54          -0.65988        0.556\n",
      "            55          -0.65988        0.556\n",
      "            56          -0.65987        0.556\n",
      "            57          -0.65987        0.556\n",
      "            58          -0.65986        0.556\n",
      "            59          -0.65986        0.556\n",
      "            60          -0.65985        0.556\n",
      "            61          -0.65985        0.556\n",
      "            62          -0.65984        0.556\n",
      "            63          -0.65984        0.556\n",
      "            64          -0.65984        0.556\n",
      "            65          -0.65983        0.556\n",
      "            66          -0.65983        0.556\n",
      "            67          -0.65982        0.556\n",
      "            68          -0.65982        0.556\n",
      "            69          -0.65982        0.556\n",
      "            70          -0.65981        0.556\n",
      "            71          -0.65981        0.556\n",
      "            72          -0.65981        0.556\n",
      "            73          -0.65980        0.556\n",
      "            74          -0.65980        0.556\n",
      "            75          -0.65980        0.556\n",
      "            76          -0.65980        0.556\n",
      "            77          -0.65979        0.556\n",
      "            78          -0.65979        0.556\n",
      "            79          -0.65979        0.556\n",
      "            80          -0.65978        0.556\n",
      "            81          -0.65978        0.556\n",
      "            82          -0.65978        0.556\n",
      "            83          -0.65978        0.556\n",
      "            84          -0.65977        0.556\n",
      "            85          -0.65977        0.556\n",
      "            86          -0.65977        0.556\n",
      "            87          -0.65977        0.556\n",
      "            88          -0.65977        0.556\n",
      "            89          -0.65976        0.556\n",
      "            90          -0.65976        0.556\n",
      "            91          -0.65976        0.556\n",
      "            92          -0.65976        0.556\n",
      "            93          -0.65976        0.556\n",
      "            94          -0.65975        0.556\n",
      "            95          -0.65975        0.556\n",
      "            96          -0.65975        0.556\n",
      "            97          -0.65975        0.556\n",
      "            98          -0.65975        0.556\n",
      "            99          -0.65974        0.556\n",
      "         Final          -0.65974        0.556\n",
      "Accuracy on the dev-test set: 0.5463623395149786 \n",
      "\n",
      "   6.644 sentiment==51.2 and label is 'bbc'\n",
      "   6.644 sentiment==55.00000000000001 and label is 'bbc'\n",
      "   6.644 sentiment==60.0 and label is 'bbc'\n",
      "   6.644 sentiment==66.10000000000001 and label is 'bbc'\n",
      "   6.644 sentiment==55.900000000000006 and label is 'bbc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetPos)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetPos), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "2a6f9dd8-4e4a-448c-ba9e-1518aa1114f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.499\n",
      "             2          -0.64564        0.594\n",
      "             3          -0.63740        0.594\n",
      "             4          -0.63248        0.594\n",
      "             5          -0.62922        0.594\n",
      "             6          -0.62689        0.594\n",
      "             7          -0.62515        0.594\n",
      "             8          -0.62380        0.594\n",
      "             9          -0.62272        0.594\n",
      "            10          -0.62184        0.594\n",
      "            11          -0.62110        0.594\n",
      "            12          -0.62048        0.594\n",
      "            13          -0.61995        0.594\n",
      "            14          -0.61949        0.594\n",
      "            15          -0.61909        0.594\n",
      "            16          -0.61873        0.594\n",
      "            17          -0.61841        0.594\n",
      "            18          -0.61813        0.594\n",
      "            19          -0.61788        0.594\n",
      "            20          -0.61765        0.594\n",
      "            21          -0.61744        0.594\n",
      "            22          -0.61725        0.594\n",
      "            23          -0.61707        0.594\n",
      "            24          -0.61691        0.594\n",
      "            25          -0.61676        0.594\n",
      "            26          -0.61662        0.594\n",
      "            27          -0.61650        0.594\n",
      "            28          -0.61638        0.594\n",
      "            29          -0.61627        0.594\n",
      "            30          -0.61616        0.594\n",
      "            31          -0.61607        0.594\n",
      "            32          -0.61597        0.594\n",
      "            33          -0.61589        0.594\n",
      "            34          -0.61581        0.594\n",
      "            35          -0.61573        0.594\n",
      "            36          -0.61566        0.594\n",
      "            37          -0.61559        0.594\n",
      "            38          -0.61553        0.594\n",
      "            39          -0.61546        0.594\n",
      "            40          -0.61540        0.594\n",
      "            41          -0.61535        0.594\n",
      "            42          -0.61530        0.594\n",
      "            43          -0.61524        0.594\n",
      "            44          -0.61520        0.594\n",
      "            45          -0.61515        0.594\n",
      "            46          -0.61510        0.594\n",
      "            47          -0.61506        0.594\n",
      "            48          -0.61502        0.594\n",
      "            49          -0.61498        0.594\n",
      "            50          -0.61494        0.594\n",
      "            51          -0.61491        0.594\n",
      "            52          -0.61487        0.594\n",
      "            53          -0.61484        0.594\n",
      "            54          -0.61481        0.594\n",
      "            55          -0.61478        0.594\n",
      "            56          -0.61474        0.594\n",
      "            57          -0.61472        0.594\n",
      "            58          -0.61469        0.594\n",
      "            59          -0.61466        0.594\n",
      "            60          -0.61463        0.594\n",
      "            61          -0.61461        0.594\n",
      "            62          -0.61458        0.594\n",
      "            63          -0.61456        0.594\n",
      "            64          -0.61454        0.594\n",
      "            65          -0.61451        0.594\n",
      "            66          -0.61449        0.594\n",
      "            67          -0.61447        0.594\n",
      "            68          -0.61445        0.594\n",
      "            69          -0.61443        0.594\n",
      "            70          -0.61441        0.594\n",
      "            71          -0.61439        0.594\n",
      "            72          -0.61437        0.594\n",
      "            73          -0.61436        0.594\n",
      "            74          -0.61434        0.594\n",
      "            75          -0.61432        0.594\n",
      "            76          -0.61431        0.594\n",
      "            77          -0.61429        0.594\n",
      "            78          -0.61427        0.594\n",
      "            79          -0.61426        0.594\n",
      "            80          -0.61424        0.594\n",
      "            81          -0.61423        0.594\n",
      "            82          -0.61422        0.594\n",
      "            83          -0.61420        0.594\n",
      "            84          -0.61419        0.594\n",
      "            85          -0.61418        0.594\n",
      "            86          -0.61416        0.594\n",
      "            87          -0.61415        0.594\n",
      "            88          -0.61414        0.594\n",
      "            89          -0.61413        0.594\n",
      "            90          -0.61411        0.594\n",
      "            91          -0.61410        0.594\n",
      "            92          -0.61409        0.594\n",
      "            93          -0.61408        0.594\n",
      "            94          -0.61407        0.594\n",
      "            95          -0.61406        0.594\n",
      "            96          -0.61405        0.594\n",
      "            97          -0.61404        0.594\n",
      "            98          -0.61403        0.594\n",
      "            99          -0.61402        0.594\n",
      "         Final          -0.61401        0.594\n",
      "Accuracy on the dev-test set: 0.5524251069900142 \n",
      "\n",
      "   6.644 sentiment==-3.8699999999999997 and label is 'abc'\n",
      "   6.644 sentiment==29.24 and label is 'bbc'\n",
      "   6.644 sentiment==-16.950000000000003 and label is 'bbc'\n",
      "   6.644 sentiment==-62.4 and label is 'bbc'\n",
      "   6.644 sentiment==-93.22 and label is 'abc'\n"
     ]
    }
   ],
   "source": [
    "# run the classifier with the trainingSet\n",
    "classifier = nltk.MaxentClassifier.train(trainingSetCom)\n",
    "\n",
    "# check accuracy on the devtestSet\n",
    "print(\"Accuracy on the dev-test set:\", nltk.classify.accuracy(classifier, devtestSetCom), \"\\n\")\n",
    "\n",
    "# check what the most informative features are in our model\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "21722634-0cb6-4669-b7c6-a423a5b27810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# create an empty list to store the errors\\nerrors = []\\n\\n# loop through the devtestNames to classify the entire name\\n# store the errors in the list\\nfor (message, tag) in testMessages:\\n    guess = B_classifier.classify(featureExtractor(str(message)))\\n    if guess != tag:\\n        print(\"correct=%s guess=%s name=%s\" % (tag, guess, message))'"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# create an empty list to store the errors\n",
    "errors = []\n",
    "\n",
    "# loop through the devtestNames to classify the entire name\n",
    "# store the errors in the list\n",
    "for (message, tag) in testMessages:\n",
    "    guess = B_classifier.classify(featureExtractor(str(message)))\n",
    "    if guess != tag:\n",
    "        print(\"correct=%s guess=%s name=%s\" % (tag, guess, message))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffaef02-0bca-4dfe-a84c-a09cf495ec17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c7cbf-1816-4d57-a1d6-715f85c200fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64431ba-2b05-4d84-8762-4f64da010b19",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "    SciKit Learn and NLTK package : https://www.youtube.com/watch?v=nla4C-VYNEU&t=272s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc7f3c-6a17-4e41-bb05-6cabe2ab0d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
